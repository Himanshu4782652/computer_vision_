{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6c68b70-85eb-4891-9c8c-c16d4c4a37c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4026855112.py, line 87)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 87\u001b[0;36m\u001b[0m\n\u001b[0;31m    for row in\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Training data\n",
    "data = [\n",
    "    [30, 'high', 'no', 'fair', 'no'],\n",
    "    [30, 'high', 'no', 'excellent', 'no'],\n",
    "    [31, 'high', 'yes', 'fair', 'no'],\n",
    "    [31, 'low', 'yes', 'fair', 'yes'],\n",
    "    [31, 'low', 'yes', 'excellent', 'yes'],\n",
    "    [31, 'medium', 'no', 'fair', 'no'],\n",
    "    [31, 'medium', 'no', 'excellent', 'yes'],\n",
    "    [31, 'medium', 'yes', 'fair', 'yes'],\n",
    "    [31, 'medium', 'yes', 'excellent', 'yes'],\n",
    "    [40, 'medium', 'no', 'fair', 'no'],\n",
    "    [40, 'low', 'yes', 'fair', 'yes'],\n",
    "    [40, 'low', 'yes', 'excellent', 'no'],\n",
    "    [40, 'medium', 'yes', 'fair', 'yes'],\n",
    "    [40, 'medium', 'no', 'excellent', 'no'],\n",
    "]\n",
    "\n",
    "# Class labels\n",
    "classes = ['no', 'yes']\n",
    "\n",
    "# Feature names\n",
    "features = ['age', 'income', 'student', 'credit_rating']\n",
    "\n",
    "# Calculate the entropy of the training data\n",
    "def entropy(data):\n",
    "    p_pos = np.count_nonzero([x[-1] == 'yes' for x in data]) / len(data)\n",
    "    p_neg = np.count_nonzero([x[-1] == 'no' for x in data]) / len(data)\n",
    "    return -p_pos * np.log2(p_pos) - p_neg * np.log2(p_neg)\n",
    "\n",
    "# Calculate the information gain of a feature\n",
    "def information_gain(data, feature):\n",
    "    data_by_feature = defaultdict(list)\n",
    "    for row in data_by_feature[row[feature]].append(row):\n",
    "        total = len(data)\n",
    "        ig = entropy(data)\n",
    "    for value, subset in data_by_feature.items():\n",
    "        p = len(subset) / total\n",
    "        ig -= p * entropy(subset)\n",
    "    return ig\n",
    "\n",
    "# Find the feature with the highest information gain\n",
    "def find_best_feature(data):\n",
    "    best_gain = 0\n",
    "    best_feature = None\n",
    "    for i in range(len(data[0])-1):\n",
    "        gain = information_gain(data, i)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_feature = i\n",
    "    return best_feature\n",
    "\n",
    "# Split the data by a feature\n",
    "def split_data(data, feature, value):\n",
    "    left = []\n",
    "    right = []\n",
    "    for row in data:\n",
    "        if row[feature] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "# Build the decision tree\n",
    "def build_tree(data):\n",
    "    if not data or len(np.unique([x[-1] for x in data])) == 1:\n",
    "        return {'feature': None, 'threshold': None, 'class': data[0][-1]}\n",
    "    feature = find_best_feature(data)\n",
    "    threshold = (np.min(data[feature]) + np.max(data[feature])) / 2\n",
    "    left, right = split_data(data, feature, threshold)\n",
    "    left_tree = build_tree(left)\n",
    "    right_tree = build_tree(right)\n",
    "    return {'feature': feature, 'threshold': threshold, 'left': left_tree, 'right': right_tree}\n",
    "\n",
    "# Classify a sample using the decision tree\n",
    "def classify(tree, sample):\n",
    "    if tree['feature'] is None:\n",
    "        return tree['class']\n",
    "    if sample[tree['feature']] < tree['threshold']:\n",
    "        return classify(tree['left'], sample)\n",
    "    return classify(tree['right'], sample)\n",
    "\n",
    "# Test the decision tree\n",
    "tree = build_tree(data)\n",
    "for row in\n",
    "    prediction = classify(tree, row)\n",
    "    print(row, prediction)\n",
    "\n",
    "# Test the decision tree on new samples\n",
    "new_samples = [\n",
    "    [30, 'high', 'no', 'fair'],\n",
    "    [40, 'medium', 'yes', 'excellent'],\n",
    "    [25, 'low', 'no', 'fair'],\n",
    "]\n",
    "for row in new_samples:\n",
    "    prediction = classify(tree, row)\n",
    "    print(row, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd66d5-fda2-4da4-85cc-57346684baaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
